{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26746,"status":"ok","timestamp":1696473158662,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"7kcAUWcsGjQI","outputId":"4496155d-bc19-40b8-d95c-bb3390ddee1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5l0j970_V19r","executionInfo":{"status":"ok","timestamp":1696473158662,"user_tz":-420,"elapsed":16,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}}},"outputs":[],"source":["#!pip install -q xlrd\n","#!git clone https://github.com/AshutoshKulkarni4998/AIDTransformer.git /content/drive/MyDrive/AIDTransformer"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1696473158663,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"yRqiQsecV89L","outputId":"4447d8e0-fe87-42c5-e2c3-eb7c55249b18"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AIDTransformer\n"]}],"source":["%cd /content/drive/MyDrive/AIDTransformer"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1696473158663,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"GWpqyW9Oef8V","outputId":"f968208d-8845-4220-870a-90200e98404a"},"outputs":[{"output_type":"stream","name":"stdout","text":[" checkpoint.pth   __pycache__\t\t\t  Testing.ipynb\n"," checkpoints\t 'Quá trình thực nghiệm.gsheet'   test.py\n"," Dataset\t  README.md\t\t\t  Training.ipynb\n"," dataset.py\t  results\t\t\t  utils\n"," model.py\t 'results(original version)'\n"," PSNR_SSIM\t  RICE.html\n"]}],"source":["# !ls"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"hwQJFW6-enEs","executionInfo":{"status":"ok","timestamp":1696473158663,"user_tz":-420,"elapsed":5,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}}},"outputs":[],"source":["#!cat test.py"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6659,"status":"ok","timestamp":1696473165318,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"Zy3mDphpgCtj","outputId":"4a43e016-e9f5-419f-bce1-485834f13b74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.7.0\n"]}],"source":["!pip install einops"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6228,"status":"ok","timestamp":1696473171536,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"QUGtV5AMgQch","outputId":"caba4079-bad3-4c9d-e732-3a1233c12ecd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ptflops\n","  Downloading ptflops-0.7.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->ptflops) (3.27.5)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->ptflops) (17.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n","Building wheels for collected packages: ptflops\n","  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ptflops: filename=ptflops-0.7-py3-none-any.whl size=11075 sha256=d9b2957db54f3f31e16c5852bbc38014505b9877a074d0d5d657658ef7f2a300\n","  Stored in directory: /root/.cache/pip/wheels/b9/54/3b/f84523431ce82e08462644d279c0e13a51a00236e237e6bc7e\n","Successfully built ptflops\n","Installing collected packages: ptflops\n","Successfully installed ptflops-0.7\n"]}],"source":["!pip install ptflops"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10266,"status":"ok","timestamp":1696473181798,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"6J4zR_zlgljg","outputId":"b0c4e5ac-0eed-46f9-9d4d-c726a744f886"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Collecting huggingface-hub (from timm)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.5)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: safetensors, huggingface-hub, timm\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.3.3 timm-0.9.7\n"]}],"source":["!pip install timm"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8682,"status":"ok","timestamp":1696473190467,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"lXaSWlG9hWCg","outputId":"a7acc5cc-a044-4934-c162-d53ec21822b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (3.27.5)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->thop) (17.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n"]}],"source":["!pip install thop"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6057,"status":"ok","timestamp":1696473196520,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"_KMEzLgw6_Y0","outputId":"b5e81691-5d01-4480-95d1-6ff8846dc624"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Connected to cloud.r-project.org (18.160.213.79)] [Co\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","\r0% [2 InRelease 15.6 kB/119 kB 13%] [3 InRelease 43.1 kB/110 kB 39%] [Connectin\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [518 kB]\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,081 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,247 kB]\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,226 kB]\n","Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,002 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,266 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,340 kB]\n","Hit:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 8,023 kB in 2s (3,783 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","wget is already the newest version (1.21.2-2ubuntu1).\n","0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"]}],"source":["!apt-get update\n","!apt-get install wget"]},{"cell_type":"code","source":["!pip install einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_iA1ZX36wBX6","executionInfo":{"status":"ok","timestamp":1696473207999,"user_tz":-420,"elapsed":11486,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}},"outputId":"c9092f7b-b017-4878-e48a-8bdaba5e36d6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"]}]},{"cell_type":"code","source":["from model import *"],"metadata":{"id":"rHZegjkrvkkA","executionInfo":{"status":"ok","timestamp":1696473213845,"user_tz":-420,"elapsed":5852,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = Network()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwpYl8kNvDMN","executionInfo":{"status":"ok","timestamp":1696473222149,"user_tz":-420,"elapsed":8319,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}},"outputId":"921f973a-8ca1-4402-c0bf-cf03fa5dee10"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"execute_result","data":{"text/plain":["Network(\n","  embed_dim=32, token_projection=conv, token_mlp=ffn,win_size=8\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (input_proj): InputProj(\n","    (proj): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): LeakyReLU(negative_slope=0.01, inplace=True)\n","    )\n","  )\n","  (output_proj): OutputProj(\n","    (proj): Sequential(\n","      (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n","  (output_proj1): OutputProj(\n","    (proj): Sequential(\n","      (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n","  (encoderlayer_0): TRANSFORMER_BLOCK(\n","    dim=32, input_resolution=(128, 128), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=32, input_resolution=(128, 128), num_heads=1, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=32, win_size=(8, 8), num_heads=1\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=32, out_features=32, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=32, out_features=128, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=128, out_features=32, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=32, input_resolution=(128, 128), num_heads=1, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=32, win_size=(8, 8), num_heads=1\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=32, out_features=32, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.014)\n","        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=32, out_features=128, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=128, out_features=32, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (dowsample_0): Downsample(\n","    (conv): Sequential(\n","      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    )\n","  )\n","  (hs_downsample): Downsample(\n","    (conv): Sequential(\n","      (0): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    )\n","  )\n","  (hs_upsample): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(96, 32, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (qs_upsample): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(160, 32, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (qs_upsample1): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (upsample_poolup1): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(96, 32, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (upsample_poolup2): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(160, 96, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (encoderlayer_1): TRANSFORMER_BLOCK(\n","    dim=96, input_resolution=(64, 64), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.029)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.043)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (dowsample_1): Downsample(\n","    (conv): Sequential(\n","      (0): Conv2d(96, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    )\n","  )\n","  (encoderlayer_2): TRANSFORMER_BLOCK(\n","    dim=160, input_resolution=(32, 32), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=160, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=160, out_features=160, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.057)\n","        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=160, out_features=640, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=640, out_features=160, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=160, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=160, out_features=160, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.071)\n","        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=160, out_features=640, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=640, out_features=160, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (dowsample_2): Downsample(\n","    (conv): Sequential(\n","      (0): Conv2d(160, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    )\n","  )\n","  (encoderlayer_3): TRANSFORMER_BLOCK(\n","    dim=256, input_resolution=(16, 16), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=256, win_size=(8, 8), num_heads=8\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=256, out_features=256, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.086)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=256, win_size=(8, 8), num_heads=8\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=256, out_features=256, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.100)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (dowsample_3): Downsample(\n","    (conv): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    )\n","  )\n","  (conv): TRANSFORMER_BLOCK(\n","    dim=288, input_resolution=(8, 8), depth=2\n","    (blocks): ModuleList(\n","      (0-1): 2 x Deformable_Attentive_Transformer(\n","        dim=288, input_resolution=(8, 8), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=288, win_size=(8, 8), num_heads=16\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n","              (pointwise): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(288, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n","              (pointwise): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(288, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n","              (pointwise): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(288, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=288, out_features=288, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.100)\n","        (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=288, out_features=1152, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=1152, out_features=288, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (upsample_0): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(288, 256, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (decoderlayer_0): TRANSFORMER_BLOCK(\n","    dim=448, input_resolution=(16, 16), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=448, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=448, win_size=(8, 8), num_heads=16\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n","              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n","              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n","              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=448, out_features=448, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.100)\n","        (norm2): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=448, out_features=1792, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=1792, out_features=448, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=448, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=448, win_size=(8, 8), num_heads=16\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n","              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n","              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n","              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=448, out_features=448, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.086)\n","        (norm2): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=448, out_features=1792, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=1792, out_features=448, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (upsample_1): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(448, 128, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (decoderlayer_1): TRANSFORMER_BLOCK(\n","    dim=256, input_resolution=(32, 32), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=256, win_size=(8, 8), num_heads=8\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=256, out_features=256, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.071)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=256, win_size=(8, 8), num_heads=8\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=256, out_features=256, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.057)\n","        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (upsample_2): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (decoderlayer_2): TRANSFORMER_BLOCK(\n","    dim=96, input_resolution=(64, 64), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.043)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.029)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (upsample_3): Upsample(\n","    (deconv): Sequential(\n","      (0): ConvTranspose2d(128, 32, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (decoderlayer_3): TRANSFORMER_BLOCK(\n","    dim=64, input_resolution=(128, 128), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=64, input_resolution=(128, 128), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=64, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n","              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n","              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n","              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=64, out_features=64, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.014)\n","        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=64, out_features=256, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=256, out_features=64, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=64, input_resolution=(128, 128), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=64, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n","              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n","              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n","              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=64, out_features=64, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=64, out_features=256, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=256, out_features=64, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (hs1): TRANSFORMER_BLOCK(\n","    dim=32, input_resolution=(64, 64), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=32, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=32, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=32, out_features=32, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.029)\n","        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=32, out_features=128, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=128, out_features=32, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=32, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=32, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=32, out_features=32, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.043)\n","        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=32, out_features=128, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=128, out_features=32, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (hs2): TRANSFORMER_BLOCK(\n","    dim=96, input_resolution=(64, 64), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.029)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.043)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (hs3): TRANSFORMER_BLOCK(\n","    dim=96, input_resolution=(64, 64), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.029)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.043)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (hs4): TRANSFORMER_BLOCK(\n","    dim=96, input_resolution=(64, 64), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.029)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=96, win_size=(8, 8), num_heads=2\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.043)\n","        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=96, out_features=384, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=384, out_features=96, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (qs1): TRANSFORMER_BLOCK(\n","    dim=32, input_resolution=(32, 32), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=32, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=32, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=32, out_features=32, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.057)\n","        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=32, out_features=128, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=128, out_features=32, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=32, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=32, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=32, out_features=32, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.071)\n","        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=32, out_features=128, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=128, out_features=32, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (qs2): TRANSFORMER_BLOCK(\n","    dim=160, input_resolution=(32, 32), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=160, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=160, out_features=160, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.057)\n","        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=160, out_features=640, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=640, out_features=160, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=160, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=160, out_features=160, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.071)\n","        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=160, out_features=640, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=640, out_features=160, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (qs3): TRANSFORMER_BLOCK(\n","    dim=160, input_resolution=(32, 32), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=160, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=160, out_features=160, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.057)\n","        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=160, out_features=640, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=640, out_features=160, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=160, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=160, out_features=160, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.071)\n","        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=160, out_features=640, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=640, out_features=160, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (qs4): TRANSFORMER_BLOCK(\n","    dim=160, input_resolution=(32, 32), depth=2\n","    (blocks): ModuleList(\n","      (0): Deformable_Attentive_Transformer(\n","        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n","        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=160, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=160, out_features=160, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.057)\n","        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=160, out_features=640, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=640, out_features=160, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (1): Deformable_Attentive_Transformer(\n","        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n","        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (attn): WindowAttention(\n","          dim=160, win_size=(8, 8), num_heads=4\n","          (qkv): ConvProjection(\n","            (to_q): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_k): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","            (to_v): SepConv2d(\n","              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n","              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n","              (act_layer): ReLU()\n","              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n","              (SA): SpatialAttention(\n","                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","                (sigmoid): Sigmoid()\n","              )\n","            )\n","          )\n","          (attn_drop): Dropout(p=0.0, inplace=False)\n","          (proj): Linear(in_features=160, out_features=160, bias=True)\n","          (se_layer): Identity()\n","          (proj_drop): Dropout(p=0.0, inplace=False)\n","          (softmax): Softmax(dim=-1)\n","        )\n","        (drop_path): DropPath(drop_prob=0.071)\n","        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Mlp(\n","          (fc1): Linear(in_features=160, out_features=640, bias=True)\n","          (act): GELU(approximate='none')\n","          (fc2): Linear(in_features=640, out_features=160, bias=True)\n","          (drop): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["!pip install torch-summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYCqEXSOx9wy","executionInfo":{"status":"ok","timestamp":1696473227790,"user_tz":-420,"elapsed":5659,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}},"outputId":"f96384a5-ffe6-4648-cf2c-630d283c969b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-summary\n","  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n","Installing collected packages: torch-summary\n","Successfully installed torch-summary-1.4.5\n"]}]},{"cell_type":"code","source":["# from torchsummary import summary\n","\n","# model = Network()\n","# summary(model,(3, 512, 512)) # cho coi shape của từng layer, para"],"metadata":{"id":"OV8Xi4_uyOSz","executionInfo":{"status":"ok","timestamp":1696473227790,"user_tz":-420,"elapsed":14,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('/content/drive/MyDrive/AIDTransformer/checkpoint.pth')[\"state_dict\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwvP_BhIwOpc","executionInfo":{"status":"ok","timestamp":1696473235134,"user_tz":-420,"elapsed":7356,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}},"outputId":"b6fa685e-20ec-4542-aa55-6c4344fdf79d"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["torch.load('/content/drive/MyDrive/AIDTransformer/checkpoint.pth')[\"epoch\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqgH-5rPuxlE","executionInfo":{"status":"ok","timestamp":1696473237186,"user_tz":-420,"elapsed":2063,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}},"outputId":"c193ca54-82cb-4edc-9ba6-9c1711f09e7d"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":662582,"status":"ok","timestamp":1696473899764,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"},"user_tz":-420},"id":"qocALBzKerDH","outputId":"535f1c7e-044b-4c61-e909-72cd88805a49"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","=======================>Testing on RICE dataset<=======================\n","  0% 0/500 [00:00<?, ?it/s]torch.Size([1, 3, 256, 256])\n","1\n","  0% 1/500 [00:03<25:17,  3.04s/it]torch.Size([1, 3, 256, 256])\n","1\n","  0% 2/500 [00:04<17:40,  2.13s/it]torch.Size([1, 3, 256, 256])\n","1\n","  1% 3/500 [00:05<15:07,  1.83s/it]torch.Size([1, 3, 256, 256])\n","1\n","  1% 4/500 [00:07<14:00,  1.69s/it]torch.Size([1, 3, 256, 256])\n","1\n","  1% 5/500 [00:09<14:01,  1.70s/it]torch.Size([1, 3, 256, 256])\n","1\n","  1% 6/500 [00:15<25:49,  3.14s/it]torch.Size([1, 3, 256, 256])\n","1\n","  1% 7/500 [00:16<21:10,  2.58s/it]torch.Size([1, 3, 256, 256])\n","1\n","  2% 8/500 [00:17<17:43,  2.16s/it]torch.Size([1, 3, 256, 256])\n","1\n","  2% 9/500 [00:19<15:26,  1.89s/it]torch.Size([1, 3, 256, 256])\n","1\n","  2% 10/500 [00:20<13:36,  1.67s/it]torch.Size([1, 3, 256, 256])\n","1\n","  2% 11/500 [00:21<12:53,  1.58s/it]torch.Size([1, 3, 256, 256])\n","1\n","  2% 12/500 [00:22<11:57,  1.47s/it]torch.Size([1, 3, 256, 256])\n","1\n","  3% 13/500 [00:24<11:07,  1.37s/it]torch.Size([1, 3, 256, 256])\n","1\n","  3% 14/500 [00:25<10:40,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n","  3% 15/500 [00:26<10:35,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n","  3% 16/500 [00:27<10:51,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n","  3% 17/500 [00:29<10:42,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n","  4% 18/500 [00:30<10:34,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n","  4% 19/500 [00:31<10:29,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n","  4% 20/500 [00:33<10:27,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n","  4% 21/500 [00:34<10:02,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n","  4% 22/500 [00:35<10:07,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n","  5% 23/500 [00:36<09:57,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n","  5% 24/500 [00:38<10:00,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n","  5% 25/500 [00:39<09:50,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n","  5% 26/500 [00:40<09:59,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n","  5% 27/500 [00:41<09:51,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n","  6% 28/500 [00:42<09:29,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n","  6% 29/500 [00:44<09:19,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n","  6% 30/500 [00:45<09:20,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n","  6% 31/500 [00:46<09:19,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n","  6% 32/500 [00:47<09:04,  1.16s/it]torch.Size([1, 3, 256, 256])\n","1\n","  7% 33/500 [00:48<08:56,  1.15s/it]torch.Size([1, 3, 256, 256])\n","1\n","  7% 34/500 [00:49<09:09,  1.18s/it]torch.Size([1, 3, 256, 256])\n","1\n","  7% 35/500 [00:50<08:58,  1.16s/it]torch.Size([1, 3, 256, 256])\n","1\n","  7% 36/500 [00:52<09:06,  1.18s/it]torch.Size([1, 3, 256, 256])\n","1\n","  7% 37/500 [00:53<09:36,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n","  8% 38/500 [00:54<09:41,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n","  8% 39/500 [00:56<09:21,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n","  8% 40/500 [00:57<09:31,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n","  8% 41/500 [00:58<09:29,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n","  8% 42/500 [00:59<09:29,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n","  9% 43/500 [01:01<09:38,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n","  9% 44/500 [01:02<09:35,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n","  9% 45/500 [01:03<09:25,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n","  9% 46/500 [01:05<09:48,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n","  9% 47/500 [01:06<09:25,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 10% 48/500 [01:07<09:34,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 10% 49/500 [01:08<09:42,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 10% 50/500 [01:10<09:40,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 10% 51/500 [01:11<09:42,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 10% 52/500 [01:12<09:25,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 11% 53/500 [01:13<09:24,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 11% 54/500 [01:15<09:10,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 11% 55/500 [01:16<09:15,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 11% 56/500 [01:17<09:41,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 11% 57/500 [01:18<09:19,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 12% 58/500 [01:20<09:33,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 12% 59/500 [01:21<09:54,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 12% 60/500 [01:23<09:46,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 12% 61/500 [01:24<09:47,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 12% 62/500 [01:25<09:26,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 13% 63/500 [01:26<09:07,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 13% 64/500 [01:28<09:11,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 13% 65/500 [01:29<09:21,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 13% 66/500 [01:30<09:23,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 13% 67/500 [01:31<09:20,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 14% 68/500 [01:33<09:05,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 14% 69/500 [01:34<09:08,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 14% 70/500 [01:35<09:17,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 14% 71/500 [01:37<09:26,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 14% 72/500 [01:38<09:23,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 15% 73/500 [01:39<09:22,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 15% 74/500 [01:41<09:28,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 15% 75/500 [01:42<09:29,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 15% 76/500 [01:43<09:24,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 15% 77/500 [01:45<09:00,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 16% 78/500 [01:46<08:49,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 16% 79/500 [01:47<08:37,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 16% 80/500 [01:48<08:49,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 16% 81/500 [01:49<08:35,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 16% 82/500 [01:51<08:28,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 17% 83/500 [01:52<08:41,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 17% 84/500 [01:53<08:46,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 17% 85/500 [01:55<08:50,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 17% 86/500 [01:56<08:59,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 17% 87/500 [01:57<08:54,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 18% 88/500 [01:58<08:42,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 18% 89/500 [02:00<08:43,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 18% 90/500 [02:01<08:34,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 18% 91/500 [02:02<08:50,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 18% 92/500 [02:03<08:41,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 19% 93/500 [02:05<08:26,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 19% 94/500 [02:06<08:42,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 19% 95/500 [02:07<08:48,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 19% 96/500 [02:09<08:53,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 19% 97/500 [02:10<08:46,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 20% 98/500 [02:11<08:52,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 20% 99/500 [02:13<08:35,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 20% 100/500 [02:14<08:36,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 20% 101/500 [02:15<08:28,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 20% 102/500 [02:16<08:18,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 21% 103/500 [02:18<08:26,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 21% 104/500 [02:19<08:34,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 21% 105/500 [02:20<08:23,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 21% 106/500 [02:21<08:14,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 21% 107/500 [02:23<07:58,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 22% 108/500 [02:24<08:11,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 22% 109/500 [02:25<08:21,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 22% 110/500 [02:26<08:16,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 22% 111/500 [02:28<08:10,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 22% 112/500 [02:29<08:06,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 23% 113/500 [02:30<08:16,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 23% 114/500 [02:32<08:21,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 23% 115/500 [02:33<08:23,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 23% 116/500 [02:34<08:04,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 23% 117/500 [02:35<07:57,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 24% 118/500 [02:37<07:53,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 24% 119/500 [02:38<07:55,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 24% 120/500 [02:39<07:55,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 24% 121/500 [02:40<08:03,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 24% 122/500 [02:42<07:53,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 25% 123/500 [02:43<08:02,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 25% 124/500 [02:44<07:50,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 25% 125/500 [02:45<07:57,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 25% 126/500 [02:47<08:05,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 25% 127/500 [02:48<08:04,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 26% 128/500 [02:49<08:05,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 26% 129/500 [02:51<08:03,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 26% 130/500 [02:52<08:06,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 26% 131/500 [02:53<08:05,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 26% 132/500 [02:55<07:58,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 27% 133/500 [02:56<07:59,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 27% 134/500 [02:57<08:12,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 27% 135/500 [02:59<08:07,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 27% 136/500 [03:00<07:48,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 27% 137/500 [03:01<07:43,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 28% 138/500 [03:02<07:43,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 28% 139/500 [03:04<07:50,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 28% 140/500 [03:05<07:35,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 28% 141/500 [03:06<07:54,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 28% 142/500 [03:08<07:49,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 29% 143/500 [03:09<07:36,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 29% 144/500 [03:10<07:42,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 29% 145/500 [03:12<07:49,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 29% 146/500 [03:13<07:48,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 29% 147/500 [03:14<07:35,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 30% 148/500 [03:16<07:38,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 30% 149/500 [03:17<07:40,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 30% 150/500 [03:18<07:58,  1.37s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 30% 151/500 [03:20<07:55,  1.36s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 30% 152/500 [03:21<08:08,  1.40s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 31% 153/500 [03:22<07:40,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 31% 154/500 [03:24<07:25,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 31% 155/500 [03:25<07:52,  1.37s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 31% 156/500 [03:27<07:52,  1.37s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 31% 157/500 [03:28<07:43,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 32% 158/500 [03:29<07:27,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 32% 159/500 [03:30<07:16,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 32% 160/500 [03:32<07:22,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 32% 161/500 [03:33<07:10,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 32% 162/500 [03:34<07:17,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 33% 163/500 [03:36<07:32,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 33% 164/500 [03:37<07:16,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 33% 165/500 [03:38<07:04,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 33% 166/500 [03:39<06:59,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 33% 167/500 [03:41<07:10,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 34% 168/500 [03:42<06:56,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 34% 169/500 [03:43<07:07,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 34% 170/500 [03:44<07:11,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 34% 171/500 [03:46<07:15,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 34% 172/500 [03:47<07:17,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 35% 173/500 [03:49<07:14,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 35% 174/500 [03:50<07:12,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 35% 175/500 [03:51<07:03,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 35% 176/500 [03:52<06:57,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 35% 177/500 [03:54<07:04,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 36% 178/500 [03:55<06:53,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 36% 179/500 [03:56<06:45,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 36% 180/500 [03:57<06:35,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 36% 181/500 [03:59<06:45,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 36% 182/500 [04:00<06:38,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 37% 183/500 [04:01<06:33,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 37% 184/500 [04:02<06:40,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 37% 185/500 [04:04<06:29,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 37% 186/500 [04:05<06:37,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 37% 187/500 [04:06<06:29,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 38% 188/500 [04:07<06:32,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 38% 189/500 [04:09<06:26,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 38% 190/500 [04:10<06:29,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 38% 191/500 [04:11<06:39,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 38% 192/500 [04:13<06:36,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 39% 193/500 [04:14<06:26,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 39% 194/500 [04:15<06:17,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 39% 195/500 [04:16<06:23,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 39% 196/500 [04:18<06:30,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 39% 197/500 [04:19<06:23,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 40% 198/500 [04:20<06:23,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 40% 199/500 [04:21<06:18,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 40% 200/500 [04:23<06:27,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 40% 201/500 [04:24<06:24,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 40% 202/500 [04:25<06:25,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 41% 203/500 [04:26<06:11,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 41% 204/500 [04:28<06:19,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 41% 205/500 [04:29<06:10,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 41% 206/500 [04:30<06:00,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 41% 207/500 [04:31<06:01,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 42% 208/500 [04:32<05:51,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 42% 209/500 [04:34<05:45,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 42% 210/500 [04:35<05:45,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 42% 211/500 [04:36<05:42,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 42% 212/500 [04:37<05:40,  1.18s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 43% 213/500 [04:38<05:39,  1.18s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 43% 214/500 [04:40<05:39,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 43% 215/500 [04:41<05:55,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 43% 216/500 [04:42<05:52,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 43% 217/500 [04:43<05:44,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 44% 218/500 [04:45<05:39,  1.20s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 44% 219/500 [04:46<05:29,  1.17s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 44% 220/500 [04:47<05:39,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 44% 221/500 [04:48<05:47,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 44% 222/500 [04:50<05:52,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 45% 223/500 [04:51<05:52,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 45% 224/500 [04:52<05:38,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 45% 225/500 [04:53<05:36,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 45% 226/500 [04:54<05:40,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 45% 227/500 [04:56<05:33,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 46% 228/500 [04:57<05:42,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 46% 229/500 [04:58<05:32,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 46% 230/500 [04:59<05:38,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 46% 231/500 [05:01<05:40,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 46% 232/500 [05:02<05:35,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 47% 233/500 [05:03<05:47,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 47% 234/500 [05:05<05:51,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 47% 235/500 [05:06<05:37,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 47% 236/500 [05:07<05:28,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 47% 237/500 [05:08<05:17,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 48% 238/500 [05:09<05:09,  1.18s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 48% 239/500 [05:11<05:19,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 48% 240/500 [05:12<05:21,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 48% 241/500 [05:13<05:17,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 48% 242/500 [05:14<05:23,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 49% 243/500 [05:16<05:16,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 49% 244/500 [05:17<05:31,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 49% 245/500 [05:18<05:20,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 49% 246/500 [05:20<05:22,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 49% 247/500 [05:21<05:29,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 50% 248/500 [05:22<05:20,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 50% 249/500 [05:23<05:10,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 50% 250/500 [05:25<05:16,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 50% 251/500 [05:26<05:14,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 50% 252/500 [05:27<05:16,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 51% 253/500 [05:28<05:15,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 51% 254/500 [05:30<05:12,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 51% 255/500 [05:31<05:13,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 51% 256/500 [05:32<05:19,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 51% 257/500 [05:34<05:06,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 52% 258/500 [05:35<05:09,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 52% 259/500 [05:36<04:57,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 52% 260/500 [05:37<04:50,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 52% 261/500 [05:38<04:53,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 52% 262/500 [05:40<04:52,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 53% 263/500 [05:41<04:49,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 53% 264/500 [05:42<04:41,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 53% 265/500 [05:43<04:40,  1.19s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 53% 266/500 [05:44<04:48,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 53% 267/500 [05:46<04:45,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 54% 268/500 [05:47<04:43,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 54% 269/500 [05:48<04:39,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 54% 270/500 [05:49<04:40,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 54% 271/500 [05:51<04:47,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 54% 272/500 [05:52<04:42,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 55% 273/500 [05:53<04:50,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 55% 274/500 [05:54<04:43,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 55% 275/500 [05:56<04:36,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 55% 276/500 [05:57<04:42,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 55% 277/500 [05:58<04:47,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 56% 278/500 [06:00<04:50,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 56% 279/500 [06:01<04:44,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 56% 280/500 [06:02<04:41,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 56% 281/500 [06:03<04:44,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 56% 282/500 [06:05<04:43,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 57% 283/500 [06:06<04:34,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 57% 284/500 [06:07<04:26,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 57% 285/500 [06:08<04:21,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 57% 286/500 [06:10<04:30,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 57% 287/500 [06:11<04:37,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 58% 288/500 [06:12<04:41,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 58% 289/500 [06:14<04:39,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 58% 290/500 [06:15<04:38,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 58% 291/500 [06:16<04:38,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 58% 292/500 [06:18<04:25,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 59% 293/500 [06:19<04:25,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 59% 294/500 [06:20<04:23,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 59% 295/500 [06:22<04:27,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 59% 296/500 [06:23<04:27,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 59% 297/500 [06:24<04:31,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 60% 298/500 [06:25<04:22,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 60% 299/500 [06:27<04:24,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 60% 300/500 [06:28<04:29,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 60% 301/500 [06:30<04:25,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 60% 302/500 [06:31<04:13,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 61% 303/500 [06:32<04:04,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 61% 304/500 [06:33<04:11,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 61% 305/500 [06:35<04:09,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 61% 306/500 [06:36<04:08,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 61% 307/500 [06:37<04:03,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 62% 308/500 [06:38<03:58,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 62% 309/500 [06:39<03:58,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 62% 310/500 [06:41<04:03,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 62% 311/500 [06:42<03:57,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 62% 312/500 [06:43<04:00,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 63% 313/500 [06:45<03:56,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 63% 314/500 [06:46<03:53,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 63% 315/500 [06:47<03:49,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 63% 316/500 [06:48<03:53,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 63% 317/500 [06:50<03:54,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 64% 318/500 [06:51<03:53,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 64% 319/500 [06:52<03:47,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 64% 320/500 [06:54<03:51,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 64% 321/500 [06:55<03:46,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 64% 322/500 [06:56<03:50,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 65% 323/500 [06:57<03:51,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 65% 324/500 [06:59<03:44,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 65% 325/500 [07:00<03:39,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 65% 326/500 [07:01<03:44,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 65% 327/500 [07:03<03:47,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 66% 328/500 [07:04<03:47,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 66% 329/500 [07:05<03:41,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 66% 330/500 [07:07<03:47,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 66% 331/500 [07:08<03:45,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 66% 332/500 [07:09<03:46,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 67% 333/500 [07:11<03:42,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 67% 334/500 [07:12<03:41,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 67% 335/500 [07:13<03:35,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 67% 336/500 [07:14<03:27,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 67% 337/500 [07:16<03:23,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 68% 338/500 [07:17<03:21,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 68% 339/500 [07:18<03:30,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 68% 340/500 [07:20<03:26,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 68% 341/500 [07:21<03:25,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 68% 342/500 [07:22<03:26,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 69% 343/500 [07:23<03:26,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 69% 344/500 [07:25<03:25,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 69% 345/500 [07:26<03:25,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 69% 346/500 [07:27<03:16,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 69% 347/500 [07:29<03:18,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 70% 348/500 [07:30<03:17,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 70% 349/500 [07:31<03:15,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 70% 350/500 [07:32<03:07,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 70% 351/500 [07:34<03:20,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 70% 352/500 [07:35<03:19,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 71% 353/500 [07:37<03:11,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 71% 354/500 [07:38<03:15,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 71% 355/500 [07:39<03:13,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 71% 356/500 [07:40<03:07,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 71% 357/500 [07:42<03:02,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 72% 358/500 [07:43<02:56,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 72% 359/500 [07:44<02:54,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 72% 360/500 [07:45<03:00,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 72% 361/500 [07:47<03:07,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 72% 362/500 [07:48<03:00,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 73% 363/500 [07:50<03:00,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 73% 364/500 [07:51<02:59,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 73% 365/500 [07:52<02:55,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 73% 366/500 [07:53<02:57,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 73% 367/500 [07:55<02:57,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 74% 368/500 [07:56<02:55,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 74% 369/500 [07:57<02:48,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 74% 370/500 [07:59<02:45,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 74% 371/500 [08:00<02:40,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 74% 372/500 [08:01<02:36,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 75% 373/500 [08:02<02:34,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 75% 374/500 [08:03<02:37,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 75% 375/500 [08:05<02:33,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 75% 376/500 [08:06<02:30,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 75% 377/500 [08:07<02:29,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 76% 378/500 [08:08<02:27,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 76% 379/500 [08:10<02:29,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 76% 380/500 [08:11<02:27,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 76% 381/500 [08:12<02:31,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 76% 382/500 [08:13<02:26,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 77% 383/500 [08:15<02:29,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 77% 384/500 [08:16<02:30,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 77% 385/500 [08:17<02:25,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 77% 386/500 [08:18<02:21,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 77% 387/500 [08:20<02:19,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 78% 388/500 [08:21<02:16,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 78% 389/500 [08:22<02:18,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 78% 390/500 [08:23<02:18,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 78% 391/500 [08:25<02:18,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 78% 392/500 [08:26<02:18,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 79% 393/500 [08:27<02:20,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 79% 394/500 [08:29<02:19,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 79% 395/500 [08:30<02:17,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 79% 396/500 [08:31<02:10,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 79% 397/500 [08:33<02:12,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 80% 398/500 [08:34<02:12,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 80% 399/500 [08:35<02:12,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 80% 400/500 [08:36<02:11,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 80% 401/500 [08:38<02:10,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 80% 402/500 [08:39<02:05,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 81% 403/500 [08:40<02:06,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 81% 404/500 [08:42<02:04,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 81% 405/500 [08:43<02:03,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 81% 406/500 [08:44<02:03,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 81% 407/500 [08:46<02:02,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 82% 408/500 [08:47<02:00,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 82% 409/500 [08:48<01:58,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 82% 410/500 [08:50<01:58,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 82% 411/500 [08:51<01:57,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 82% 412/500 [08:52<01:51,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 83% 413/500 [08:53<01:53,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 83% 414/500 [08:55<01:52,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 83% 415/500 [08:56<01:48,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 83% 416/500 [08:57<01:45,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 83% 417/500 [08:58<01:45,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 84% 418/500 [09:00<01:42,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 84% 419/500 [09:01<01:39,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 84% 420/500 [09:02<01:43,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 84% 421/500 [09:04<01:43,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 84% 422/500 [09:05<01:43,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 85% 423/500 [09:06<01:40,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 85% 424/500 [09:08<01:39,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 85% 425/500 [09:09<01:39,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 85% 426/500 [09:11<01:43,  1.40s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 85% 427/500 [09:12<01:40,  1.38s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 86% 428/500 [09:13<01:36,  1.34s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 86% 429/500 [09:14<01:31,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 86% 430/500 [09:15<01:28,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 86% 431/500 [09:17<01:26,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 86% 432/500 [09:18<01:24,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 87% 433/500 [09:19<01:24,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 87% 434/500 [09:21<01:24,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 87% 435/500 [09:22<01:21,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 87% 436/500 [09:23<01:19,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 87% 437/500 [09:24<01:17,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 88% 438/500 [09:25<01:16,  1.23s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 88% 439/500 [09:27<01:16,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 88% 440/500 [09:28<01:14,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 88% 441/500 [09:29<01:17,  1.32s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 88% 442/500 [09:31<01:14,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 89% 443/500 [09:32<01:12,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 89% 444/500 [09:33<01:10,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 89% 445/500 [09:34<01:07,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 89% 446/500 [09:35<01:05,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 89% 447/500 [09:37<01:04,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 90% 448/500 [09:38<01:02,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 90% 449/500 [09:39<01:04,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 90% 450/500 [09:41<01:03,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 90% 451/500 [09:42<01:02,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 90% 452/500 [09:43<01:02,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 91% 453/500 [09:44<01:01,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 91% 454/500 [09:46<00:59,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 91% 455/500 [09:47<00:57,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 91% 456/500 [09:48<00:57,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 91% 457/500 [09:50<00:55,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 92% 458/500 [09:51<00:53,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 92% 459/500 [09:52<00:53,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 92% 460/500 [09:53<00:51,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 92% 461/500 [09:55<00:48,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 92% 462/500 [09:56<00:46,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 93% 463/500 [09:57<00:44,  1.21s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 93% 464/500 [09:58<00:43,  1.20s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 93% 465/500 [09:59<00:42,  1.22s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 93% 466/500 [10:01<00:42,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 93% 467/500 [10:02<00:41,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 94% 468/500 [10:03<00:40,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 94% 469/500 [10:05<00:40,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 94% 470/500 [10:06<00:39,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 94% 471/500 [10:07<00:38,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 94% 472/500 [10:09<00:36,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 95% 473/500 [10:10<00:35,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 95% 474/500 [10:11<00:34,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 95% 475/500 [10:12<00:32,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 95% 476/500 [10:14<00:30,  1.26s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 95% 477/500 [10:15<00:28,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 96% 478/500 [10:16<00:28,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 96% 479/500 [10:17<00:27,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 96% 480/500 [10:19<00:26,  1.33s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 96% 481/500 [10:20<00:25,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 96% 482/500 [10:21<00:23,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 97% 483/500 [10:23<00:21,  1.25s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 97% 484/500 [10:24<00:19,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 97% 485/500 [10:25<00:18,  1.24s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 97% 486/500 [10:26<00:17,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 97% 487/500 [10:28<00:17,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 98% 488/500 [10:29<00:15,  1.28s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 98% 489/500 [10:30<00:14,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 98% 490/500 [10:32<00:14,  1.46s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 98% 491/500 [10:34<00:12,  1.41s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 98% 492/500 [10:35<00:10,  1.35s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 99% 493/500 [10:36<00:09,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 99% 494/500 [10:37<00:07,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 99% 495/500 [10:38<00:06,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 99% 496/500 [10:40<00:05,  1.27s/it]torch.Size([1, 3, 256, 256])\n","1\n"," 99% 497/500 [10:41<00:03,  1.29s/it]torch.Size([1, 3, 256, 256])\n","1\n","100% 498/500 [10:42<00:02,  1.30s/it]torch.Size([1, 3, 256, 256])\n","1\n","100% 499/500 [10:44<00:01,  1.31s/it]torch.Size([1, 3, 256, 256])\n","1\n","100% 500/500 [10:45<00:00,  1.29s/it]\n"]}],"source":["!python test.py --dataset RICE --embed_dim 32"]},{"cell_type":"code","source":[],"metadata":{"id":"tsvL3hVrSB7D","executionInfo":{"status":"ok","timestamp":1696473899766,"user_tz":-420,"elapsed":21,"user":{"displayName":"Anh Phạm Thị Trâm","userId":"15461037140885299192"}}},"execution_count":18,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}