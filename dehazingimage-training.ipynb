{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1892e9ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:13.174520Z",
     "iopub.status.busy": "2023-10-07T16:02:13.174149Z",
     "iopub.status.idle": "2023-10-07T16:02:17.383190Z",
     "shell.execute_reply": "2023-10-07T16:02:17.382291Z"
    },
    "executionInfo": {
     "elapsed": 4613,
     "status": "ok",
     "timestamp": 1696476852602,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "o7CUi7JYIX77",
    "papermill": {
     "duration": 4.22042,
     "end_time": "2023-10-07T16:02:17.385337",
     "exception": false,
     "start_time": "2023-10-07T16:02:13.164917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed4fecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:17.402345Z",
     "iopub.status.busy": "2023-10-07T16:02:17.401748Z",
     "iopub.status.idle": "2023-10-07T16:02:17.405856Z",
     "shell.execute_reply": "2023-10-07T16:02:17.404938Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696476852602,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "u_kEpn4ffdGh",
    "papermill": {
     "duration": 0.0142,
     "end_time": "2023-10-07T16:02:17.407379",
     "exception": false,
     "start_time": "2023-10-07T16:02:17.393179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16, VGG16_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167f2ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:17.424283Z",
     "iopub.status.busy": "2023-10-07T16:02:17.423537Z",
     "iopub.status.idle": "2023-10-07T16:02:17.431344Z",
     "shell.execute_reply": "2023-10-07T16:02:17.430147Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696476852602,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "MarrvykCQrXr",
    "outputId": "1a7d40e3-d9d9-498f-e5fb-677eb0e3da91",
    "papermill": {
     "duration": 0.017879,
     "end_time": "2023-10-07T16:02:17.433053",
     "exception": false,
     "start_time": "2023-10-07T16:02:17.415174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/aidtransformer\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/input/aidtransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375435c",
   "metadata": {
    "id": "kYUcrZfYPO34",
    "papermill": {
     "duration": 0.007222,
     "end_time": "2023-10-07T16:02:17.447854",
     "exception": false,
     "start_time": "2023-10-07T16:02:17.440632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b44ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:17.464027Z",
     "iopub.status.busy": "2023-10-07T16:02:17.463186Z",
     "iopub.status.idle": "2023-10-07T16:02:28.162649Z",
     "shell.execute_reply": "2023-10-07T16:02:28.161365Z"
    },
    "papermill": {
     "duration": 10.709688,
     "end_time": "2023-10-07T16:02:28.164663",
     "exception": false,
     "start_time": "2023-10-07T16:02:17.454975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/dehazingimagesnatsort/natsort-8.4.0-py3-none-any.whl\r\n",
      "Installing collected packages: natsort\r\n",
      "Successfully installed natsort-8.4.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install /kaggle/input/dehazingimagesnatsort/natsort-8.4.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2972fb5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:28.181584Z",
     "iopub.status.busy": "2023-10-07T16:02:28.181310Z",
     "iopub.status.idle": "2023-10-07T16:02:28.450517Z",
     "shell.execute_reply": "2023-10-07T16:02:28.449490Z"
    },
    "executionInfo": {
     "elapsed": 3516,
     "status": "ok",
     "timestamp": 1696476856114,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "1pmsFwJFPd1_",
    "papermill": {
     "duration": 0.280317,
     "end_time": "2023-10-07T16:02:28.452781",
     "exception": false,
     "start_time": "2023-10-07T16:02:28.172464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1cdfc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:28.471209Z",
     "iopub.status.busy": "2023-10-07T16:02:28.470647Z",
     "iopub.status.idle": "2023-10-07T16:02:28.475222Z",
     "shell.execute_reply": "2023-10-07T16:02:28.474354Z"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1696476856115,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "S3mz4qFgPQg5",
    "papermill": {
     "duration": 0.014801,
     "end_time": "2023-10-07T16:02:28.476884",
     "exception": false,
     "start_time": "2023-10-07T16:02:28.462083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Dataset = '/kaggle/input/dehazingimagesdata/Dataset/Training_data/RICE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb478b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:28.493876Z",
     "iopub.status.busy": "2023-10-07T16:02:28.493326Z",
     "iopub.status.idle": "2023-10-07T16:02:28.819189Z",
     "shell.execute_reply": "2023-10-07T16:02:28.818270Z"
    },
    "executionInfo": {
     "elapsed": 9523,
     "status": "ok",
     "timestamp": 1696476865620,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "fJK07oWqZGdy",
    "papermill": {
     "duration": 0.336542,
     "end_time": "2023-10-07T16:02:28.821222",
     "exception": false,
     "start_time": "2023-10-07T16:02:28.484680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the data loader\n",
    "data_loader = DataLoaderTrain(rgb_dir=Dataset, img_options={'patch_size': 256})\n",
    "\n",
    "# Create the data loader\n",
    "# data_loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f02b163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:28.838123Z",
     "iopub.status.busy": "2023-10-07T16:02:28.837285Z",
     "iopub.status.idle": "2023-10-07T16:02:28.841522Z",
     "shell.execute_reply": "2023-10-07T16:02:28.840738Z"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1696476865620,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "YWWWWJJRqB5M",
    "papermill": {
     "duration": 0.014364,
     "end_time": "2023-10-07T16:02:28.843364",
     "exception": false,
     "start_time": "2023-10-07T16:02:28.829000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# path = '/content/drive/MyDrive/AIDTransformer/testing_data/RICE/input/0.png'\n",
    "\n",
    "# img = cv2.imread(path)\n",
    "# img.shape\n",
    "# #cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee5c8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:28.859747Z",
     "iopub.status.busy": "2023-10-07T16:02:28.858936Z",
     "iopub.status.idle": "2023-10-07T16:02:28.976966Z",
     "shell.execute_reply": "2023-10-07T16:02:28.975917Z"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1696476865621,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "ojp21fIEwDYI",
    "outputId": "3492744b-a8af-43c7-f0aa-47cf35be45a0",
    "papermill": {
     "duration": 0.128168,
     "end_time": "2023-10-07T16:02:28.978933",
     "exception": false,
     "start_time": "2023-10-07T16:02:28.850765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "data_loader\n",
    "len(data_loader)\n",
    "print(len(data_loader[499]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6d6e6",
   "metadata": {
    "id": "D02Cn4jtOuQP",
    "papermill": {
     "duration": 0.008,
     "end_time": "2023-10-07T16:02:28.995419",
     "exception": false,
     "start_time": "2023-10-07T16:02:28.987419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4b3786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:29.012946Z",
     "iopub.status.busy": "2023-10-07T16:02:29.012053Z",
     "iopub.status.idle": "2023-10-07T16:02:37.460242Z",
     "shell.execute_reply": "2023-10-07T16:02:37.459095Z"
    },
    "executionInfo": {
     "elapsed": 6753,
     "status": "ok",
     "timestamp": 1696476874959,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "IDgXtpfgdrVt",
    "outputId": "c997ab63-bb35-4e04-a108-d8e601d8ab68",
    "papermill": {
     "duration": 8.459259,
     "end_time": "2023-10-07T16:02:37.462548",
     "exception": false,
     "start_time": "2023-10-07T16:02:29.003289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.7)\r\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.0.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.15.1)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.4)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.3.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2023.9.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.66.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (21.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.23.5)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1f35cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:37.524078Z",
     "iopub.status.busy": "2023-10-07T16:02:37.523688Z",
     "iopub.status.idle": "2023-10-07T16:02:45.727079Z",
     "shell.execute_reply": "2023-10-07T16:02:45.725902Z"
    },
    "executionInfo": {
     "elapsed": 5922,
     "status": "ok",
     "timestamp": 1696476880873,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "x-xOIRUWd5_F",
    "outputId": "9964049a-9646-4208-ab8c-4c09dbff0a09",
    "papermill": {
     "duration": 8.215894,
     "end_time": "2023-10-07T16:02:45.729295",
     "exception": false,
     "start_time": "2023-10-07T16:02:37.513401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/dehazingimageeinops/einops-0.7.0-py3-none-any.whl\r\n",
      "Installing collected packages: einops\r\n",
      "Successfully installed einops-0.7.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/dehazingimageeinops/einops-0.7.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db885841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:45.747828Z",
     "iopub.status.busy": "2023-10-07T16:02:45.747496Z",
     "iopub.status.idle": "2023-10-07T16:02:48.700617Z",
     "shell.execute_reply": "2023-10-07T16:02:48.699665Z"
    },
    "executionInfo": {
     "elapsed": 1420,
     "status": "ok",
     "timestamp": 1696476882289,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "ayrvIv_tcUif",
    "papermill": {
     "duration": 2.964656,
     "end_time": "2023-10-07T16:02:48.702787",
     "exception": false,
     "start_time": "2023-10-07T16:02:45.738131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee9798de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:48.721536Z",
     "iopub.status.busy": "2023-10-07T16:02:48.721146Z",
     "iopub.status.idle": "2023-10-07T16:02:49.556821Z",
     "shell.execute_reply": "2023-10-07T16:02:49.555650Z"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1696476882870,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "4A8jIFvDJJqL",
    "outputId": "735a9715-948e-4144-f36a-d5854ce0c346",
    "papermill": {
     "duration": 0.84736,
     "end_time": "2023-10-07T16:02:49.559259",
     "exception": false,
     "start_time": "2023-10-07T16:02:48.711899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539f5ed",
   "metadata": {
    "id": "D4MvvP5gM4On",
    "papermill": {
     "duration": 0.008109,
     "end_time": "2023-10-07T16:02:49.576941",
     "exception": false,
     "start_time": "2023-10-07T16:02:49.568832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# perpectual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0243727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:49.595170Z",
     "iopub.status.busy": "2023-10-07T16:02:49.594757Z",
     "iopub.status.idle": "2023-10-07T16:02:49.701261Z",
     "shell.execute_reply": "2023-10-07T16:02:49.700267Z"
    },
    "papermill": {
     "duration": 0.117675,
     "end_time": "2023-10-07T16:02:49.703417",
     "exception": false,
     "start_time": "2023-10-07T16:02:49.585742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")\n",
    "else: \n",
    "    print(\"using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ded8e53f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:49.722441Z",
     "iopub.status.busy": "2023-10-07T16:02:49.721851Z",
     "iopub.status.idle": "2023-10-07T16:02:58.041060Z",
     "shell.execute_reply": "2023-10-07T16:02:58.039760Z"
    },
    "executionInfo": {
     "elapsed": 12373,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "TpmD7w5afbCM",
    "outputId": "bb9ebff8-d773-497b-966d-a7054ea36d1c",
    "papermill": {
     "duration": 8.332532,
     "end_time": "2023-10-07T16:02:58.044824",
     "exception": false,
     "start_time": "2023-10-07T16:02:49.712292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 214MB/s]\n"
     ]
    }
   ],
   "source": [
    "vgg_model = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    vgg_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ecb4003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.105748Z",
     "iopub.status.busy": "2023-10-07T16:02:58.105264Z",
     "iopub.status.idle": "2023-10-07T16:02:58.110518Z",
     "shell.execute_reply": "2023-10-07T16:02:58.109543Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "KalNgyifiMLe",
    "papermill": {
     "duration": 0.040424,
     "end_time": "2023-10-07T16:02:58.115619",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.075195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d21c6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.174283Z",
     "iopub.status.busy": "2023-10-07T16:02:58.173853Z",
     "iopub.status.idle": "2023-10-07T16:02:58.186978Z",
     "shell.execute_reply": "2023-10-07T16:02:58.185888Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "5h_hW2X6iEpl",
    "papermill": {
     "duration": 0.045033,
     "end_time": "2023-10-07T16:02:58.189619",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.144586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LossOutput = namedtuple(\"LossOutput\", [\"relu1_2\", \"relu2_2\", \"relu3_3\"])\n",
    "\n",
    "class LossNetwork(torch.nn.Module):\n",
    "    def __init__(self, vgg_model):\n",
    "        super(LossNetwork, self).__init__()\n",
    "        self.vgg_layers = vgg_model.features\n",
    "        self.layer_name_mapping = {\n",
    "            '3': \"relu1_2\",\n",
    "            '8': \"relu2_2\",\n",
    "            '15': \"relu3_3\"\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "        for name, module in self.vgg_layers._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.layer_name_mapping:\n",
    "                output[self.layer_name_mapping[name]] = x\n",
    "        return LossOutput(**output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80a4ae75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.247821Z",
     "iopub.status.busy": "2023-10-07T16:02:58.247445Z",
     "iopub.status.idle": "2023-10-07T16:02:58.257573Z",
     "shell.execute_reply": "2023-10-07T16:02:58.256587Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "VthXXK-nWnBe",
    "papermill": {
     "duration": 0.042198,
     "end_time": "2023-10-07T16:02:58.260566",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.218368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming output and ground_truth are your output and ground truth images\n",
    "loss_network = LossNetwork(vgg_model)\n",
    "loss_network.eval()\n",
    "def perpectual_loss(y_pred, y_train):\n",
    "  output_features = loss_network(y_pred)\n",
    "  ground_truth_features = loss_network(y_train)\n",
    "\n",
    "  # Calculate the perceptual loss\n",
    "  perceptual_loss = 0\n",
    "  for output_feature, ground_truth_feature in zip(output_features, ground_truth_features):\n",
    "      perceptual_loss += torch.nn.functional.l1_loss(output_feature, ground_truth_feature)\n",
    "  return perceptual_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f95e2a",
   "metadata": {
    "id": "jF7RtGHLM9dY",
    "papermill": {
     "duration": 0.027729,
     "end_time": "2023-10-07T16:02:58.316470",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.288741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# edge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f626988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.373363Z",
     "iopub.status.busy": "2023-10-07T16:02:58.372929Z",
     "iopub.status.idle": "2023-10-07T16:02:58.377754Z",
     "shell.execute_reply": "2023-10-07T16:02:58.376546Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "aPSXpX20beVu",
    "papermill": {
     "duration": 0.038276,
     "end_time": "2023-10-07T16:02:58.382517",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.344241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "128cafe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.443472Z",
     "iopub.status.busy": "2023-10-07T16:02:58.442995Z",
     "iopub.status.idle": "2023-10-07T16:02:58.456204Z",
     "shell.execute_reply": "2023-10-07T16:02:58.455115Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "5BbK9qg-i2Jt",
    "papermill": {
     "duration": 0.048134,
     "end_time": "2023-10-07T16:02:58.459617",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.411483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sobel_edge_loss(img):\n",
    "    #print('sobel')\n",
    "    print(img.shape)\n",
    "    #print(type(img))\n",
    "    #img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    sobel_kernel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).expand(-1, 3, -1, -1)\n",
    "    sobel_kernel_y = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0).expand(-1, 3, -1, -1)\n",
    "\n",
    "    sobel_kernel_x = sobel_kernel_x.to(img.device)\n",
    "    sobel_kernel_y = sobel_kernel_y.to(img.device)\n",
    "\n",
    "    edges_x = F.conv2d(img, sobel_kernel_x, padding=0)\n",
    "    edges_y = F.conv2d(img, sobel_kernel_y, padding=0)\n",
    "\n",
    "    edges = torch.sqrt(edges_x**2 + edges_y**2)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d243595d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.519722Z",
     "iopub.status.busy": "2023-10-07T16:02:58.519208Z",
     "iopub.status.idle": "2023-10-07T16:02:58.527676Z",
     "shell.execute_reply": "2023-10-07T16:02:58.526651Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "ueEpqIgAi-PQ",
    "papermill": {
     "duration": 0.041482,
     "end_time": "2023-10-07T16:02:58.530820",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.489338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def edge_loss(output, target):\n",
    "\n",
    "    output_edges = sobel_edge_loss(output)\n",
    "    target_edges = sobel_edge_loss(target)\n",
    "\n",
    "    loss = F.l1_loss(output_edges, target_edges)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b0ae4",
   "metadata": {
    "id": "otE9w6xQNDRu",
    "papermill": {
     "duration": 0.028871,
     "end_time": "2023-10-07T16:02:58.589691",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.560820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# L1 Loss và Total Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a486bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.647926Z",
     "iopub.status.busy": "2023-10-07T16:02:58.647450Z",
     "iopub.status.idle": "2023-10-07T16:02:58.652628Z",
     "shell.execute_reply": "2023-10-07T16:02:58.651663Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "aZmBgenuMg4h",
    "papermill": {
     "duration": 0.039626,
     "end_time": "2023-10-07T16:02:58.657622",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.617996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2ca661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.716745Z",
     "iopub.status.busy": "2023-10-07T16:02:58.716298Z",
     "iopub.status.idle": "2023-10-07T16:02:58.725479Z",
     "shell.execute_reply": "2023-10-07T16:02:58.724527Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696476895241,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "1J6lrFmMJRP5",
    "papermill": {
     "duration": 0.043388,
     "end_time": "2023-10-07T16:02:58.728726",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.685338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "L1_Loss = nn.L1Loss()\n",
    "def loss_function(y_pred, y_train):\n",
    "  loss1 = L1_Loss(y_pred, y_train)\n",
    "  loss2 = edge_loss(y_pred, y_train)\n",
    "  loss3 = perpectual_loss(y_pred, y_train)\n",
    "\n",
    "  total_loss = 1*loss1 + 5*loss2 + 10*loss3\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e477e",
   "metadata": {
    "id": "lebLsDoBa_AW",
    "papermill": {
     "duration": 0.029778,
     "end_time": "2023-10-07T16:02:58.787181",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.757403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d4ff7e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:58.846936Z",
     "iopub.status.busy": "2023-10-07T16:02:58.846454Z",
     "iopub.status.idle": "2023-10-07T16:02:59.071784Z",
     "shell.execute_reply": "2023-10-07T16:02:59.070721Z"
    },
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1696476895865,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "JLu9jyE9jATP",
    "outputId": "83db20ca-2946-48bc-d8bc-5cb3c95c49c2",
    "papermill": {
     "duration": 0.263821,
     "end_time": "2023-10-07T16:02:59.080613",
     "exception": false,
     "start_time": "2023-10-07T16:02:58.816792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  embed_dim=32, token_projection=conv, token_mlp=ffn,win_size=8\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (input_proj): InputProj(\n",
       "    (proj): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (output_proj): OutputProj(\n",
       "    (proj): Sequential(\n",
       "      (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (output_proj1): OutputProj(\n",
       "    (proj): Sequential(\n",
       "      (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (encoderlayer_0): TRANSFORMER_BLOCK(\n",
       "    dim=32, input_resolution=(128, 128), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=32, input_resolution=(128, 128), num_heads=1, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=32, win_size=(8, 8), num_heads=1\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=32, input_resolution=(128, 128), num_heads=1, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=32, win_size=(8, 8), num_heads=1\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dowsample_0): Downsample(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (hs_downsample): Downsample(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (hs_upsample): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(96, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (qs_upsample): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(160, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (qs_upsample1): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (upsample_poolup1): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(96, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (upsample_poolup2): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(160, 96, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (encoderlayer_1): TRANSFORMER_BLOCK(\n",
       "    dim=96, input_resolution=(64, 64), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dowsample_1): Downsample(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(96, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (encoderlayer_2): TRANSFORMER_BLOCK(\n",
       "    dim=160, input_resolution=(32, 32), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=160, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=160, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dowsample_2): Downsample(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(160, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (encoderlayer_3): TRANSFORMER_BLOCK(\n",
       "    dim=256, input_resolution=(16, 16), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=256, win_size=(8, 8), num_heads=8\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.086)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=256, win_size=(8, 8), num_heads=8\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dowsample_3): Downsample(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (conv): TRANSFORMER_BLOCK(\n",
       "    dim=288, input_resolution=(8, 8), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x Deformable_Attentive_Transformer(\n",
       "        dim=288, input_resolution=(8, 8), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=288, win_size=(8, 8), num_heads=16\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
       "              (pointwise): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(288, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
       "              (pointwise): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(288, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)\n",
       "              (pointwise): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(288, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((288,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=288, out_features=1152, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1152, out_features=288, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsample_0): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(288, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (decoderlayer_0): TRANSFORMER_BLOCK(\n",
       "    dim=448, input_resolution=(16, 16), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=448, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=448, win_size=(8, 8), num_heads=16\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n",
       "              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n",
       "              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n",
       "              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=448, out_features=448, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=448, out_features=1792, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1792, out_features=448, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=448, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=448, win_size=(8, 8), num_heads=16\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n",
       "              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n",
       "              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=448)\n",
       "              (pointwise): Conv2d(448, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(448, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=448, out_features=448, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.086)\n",
       "        (norm2): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=448, out_features=1792, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1792, out_features=448, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsample_1): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(448, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (decoderlayer_1): TRANSFORMER_BLOCK(\n",
       "    dim=256, input_resolution=(32, 32), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=256, win_size=(8, 8), num_heads=8\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=256, win_size=(8, 8), num_heads=8\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(256, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsample_2): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (decoderlayer_2): TRANSFORMER_BLOCK(\n",
       "    dim=96, input_resolution=(64, 64), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsample_3): Upsample(\n",
       "    (deconv): Sequential(\n",
       "      (0): ConvTranspose2d(128, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (decoderlayer_3): TRANSFORMER_BLOCK(\n",
       "    dim=64, input_resolution=(128, 128), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=64, input_resolution=(128, 128), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=64, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=64, input_resolution=(128, 128), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=64, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "              (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(64, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hs1): TRANSFORMER_BLOCK(\n",
       "    dim=32, input_resolution=(64, 64), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=32, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=32, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=32, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=32, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hs2): TRANSFORMER_BLOCK(\n",
       "    dim=96, input_resolution=(64, 64), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hs3): TRANSFORMER_BLOCK(\n",
       "    dim=96, input_resolution=(64, 64), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hs4): TRANSFORMER_BLOCK(\n",
       "    dim=96, input_resolution=(64, 64), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=96, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=96, win_size=(8, 8), num_heads=2\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "              (pointwise): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(96, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qs1): TRANSFORMER_BLOCK(\n",
       "    dim=32, input_resolution=(32, 32), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=32, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=32, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=32, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=32, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "              (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(32, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qs2): TRANSFORMER_BLOCK(\n",
       "    dim=160, input_resolution=(32, 32), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=160, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=160, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qs3): TRANSFORMER_BLOCK(\n",
       "    dim=160, input_resolution=(32, 32), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=160, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=160, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qs4): TRANSFORMER_BLOCK(\n",
       "    dim=160, input_resolution=(32, 32), depth=2\n",
       "    (blocks): ModuleList(\n",
       "      (0): Deformable_Attentive_Transformer(\n",
       "        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=160, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Deformable_Attentive_Transformer(\n",
       "        dim=160, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0\n",
       "        (norm1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): WindowAttention(\n",
       "          dim=160, win_size=(8, 8), num_heads=4\n",
       "          (qkv): ConvProjection(\n",
       "            (to_q): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_k): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "            (to_v): SepConv2d(\n",
       "              (depthwise): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "              (pointwise): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act_layer): ReLU()\n",
       "              (offset_conv1): Conv2d(160, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (deform1): DeformConv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
       "              (SA): SpatialAttention(\n",
       "                (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "                (sigmoid): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "          (se_layer): Identity()\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fe4771d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:02:59.152598Z",
     "iopub.status.busy": "2023-10-07T16:02:59.152282Z",
     "iopub.status.idle": "2023-10-07T16:03:08.078706Z",
     "shell.execute_reply": "2023-10-07T16:03:08.077554Z"
    },
    "executionInfo": {
     "elapsed": 3735,
     "status": "ok",
     "timestamp": 1696476899598,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "iYN12YH5OLhN",
    "outputId": "beaca0fb-6d21-462a-c78c-ba20574bf3bc",
    "papermill": {
     "duration": 8.964405,
     "end_time": "2023-10-07T16:03:08.081061",
     "exception": false,
     "start_time": "2023-10-07T16:02:59.116656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d61fb096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:08.106163Z",
     "iopub.status.busy": "2023-10-07T16:03:08.105866Z",
     "iopub.status.idle": "2023-10-07T16:03:08.110547Z",
     "shell.execute_reply": "2023-10-07T16:03:08.109472Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1696476899598,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "IpYrHzzNOY81",
    "papermill": {
     "duration": 0.01924,
     "end_time": "2023-10-07T16:03:08.112392",
     "exception": false,
     "start_time": "2023-10-07T16:03:08.093152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef326964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:08.137500Z",
     "iopub.status.busy": "2023-10-07T16:03:08.137243Z",
     "iopub.status.idle": "2023-10-07T16:03:08.143789Z",
     "shell.execute_reply": "2023-10-07T16:03:08.142846Z"
    },
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1696476900228,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "rwre64I_Opur",
    "papermill": {
     "duration": 0.021105,
     "end_time": "2023-10-07T16:03:08.145498",
     "exception": false,
     "start_time": "2023-10-07T16:03:08.124393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand2square(timg,factor=32.0):\n",
    "    timg = timg.unsqueeze(0)\n",
    "    _, _, h, w = timg.size()\n",
    "\n",
    "    X = int(math.ceil(max(h,w)/float(factor))*factor)\n",
    "\n",
    "    img = torch.zeros(1,3,X,X).type_as(timg) # 3, h,w\n",
    "    mask = torch.zeros(1,1,X,X).type_as(timg)\n",
    "\n",
    "\n",
    "    img[:,:, ((X - h)//2):((X - h)//2 + h),((X - w)//2):((X - w)//2 + w)] = timg\n",
    "    mask[:,:, ((X - h)//2):((X - h)//2 + h),((X - w)//2):((X - w)//2 + w)].fill_(1.0)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1af6c418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:08.169486Z",
     "iopub.status.busy": "2023-10-07T16:03:08.169250Z",
     "iopub.status.idle": "2023-10-07T16:03:08.173357Z",
     "shell.execute_reply": "2023-10-07T16:03:08.172213Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696476900228,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "1CX-VbP88A41",
    "papermill": {
     "duration": 0.018299,
     "end_time": "2023-10-07T16:03:08.175149",
     "exception": false,
     "start_time": "2023-10-07T16:03:08.156850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(data_loader[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1b3a837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:08.200082Z",
     "iopub.status.busy": "2023-10-07T16:03:08.199835Z",
     "iopub.status.idle": "2023-10-07T16:03:08.203461Z",
     "shell.execute_reply": "2023-10-07T16:03:08.202546Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696476900228,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "uGnDZv4tg23G",
    "papermill": {
     "duration": 0.017973,
     "end_time": "2023-10-07T16:03:08.205161",
     "exception": false,
     "start_time": "2023-10-07T16:03:08.187188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_loader[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14d04c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:08.228848Z",
     "iopub.status.busy": "2023-10-07T16:03:08.228329Z",
     "iopub.status.idle": "2023-10-07T16:03:08.232717Z",
     "shell.execute_reply": "2023-10-07T16:03:08.231925Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696476900229,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "QYwlzLzcjULw",
    "papermill": {
     "duration": 0.01814,
     "end_time": "2023-10-07T16:03:08.234391",
     "exception": false,
     "start_time": "2023-10-07T16:03:08.216251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a70447a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:08.258139Z",
     "iopub.status.busy": "2023-10-07T16:03:08.257410Z",
     "iopub.status.idle": "2023-10-07T16:03:08.261553Z",
     "shell.execute_reply": "2023-10-07T16:03:08.260762Z"
    },
    "executionInfo": {
     "elapsed": 6800,
     "status": "ok",
     "timestamp": 1696476907024,
     "user": {
      "displayName": "Anh Phạm Thị Trâm",
      "userId": "15461037140885299192"
     },
     "user_tz": -420
    },
    "id": "tAQ5n-y61HxS",
    "outputId": "1fb81668-3c4c-4ea1-c611-554e53c855ef",
    "papermill": {
     "duration": 0.017575,
     "end_time": "2023-10-07T16:03:08.263168",
     "exception": false,
     "start_time": "2023-10-07T16:03:08.245593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('/content/drive/MyDrive/AIDTransformer/checkpoint.pth')\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0002)\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max = 100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb0ad709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:08.287641Z",
     "iopub.status.busy": "2023-10-07T16:03:08.286908Z",
     "iopub.status.idle": "2023-10-07T16:03:54.129159Z",
     "shell.execute_reply": "2023-10-07T16:03:54.127798Z"
    },
    "id": "dTGgCvq_N5Se",
    "outputId": "052873e4-68d9-4729-c295-45e23295bf28",
    "papermill": {
     "duration": 45.858077,
     "end_time": "2023-10-07T16:03:54.132261",
     "exception": false,
     "start_time": "2023-10-07T16:03:08.274184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/736 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "0 0\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/736 [00:10<2:05:00, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "0 1\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/736 [00:13<1:12:47,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "0 2\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/736 [00:16<56:20,  4.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "0 3\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/736 [00:19<48:31,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "0 4\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/736 [00:22<44:11,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "0 5\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/736 [00:25<1:01:26,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.9995e-04.\n",
      "Epoch number: 0 and the loss : 17.148059844970703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/736 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "1 0\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/736 [00:02<36:35,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "1 1\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/736 [00:06<36:55,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "1 2\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/736 [00:09<37:01,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "1 3\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/736 [00:12<37:05,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "1 4\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/736 [00:15<37:06,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "1 5\n",
      "1\n",
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/736 [00:18<44:30,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.9980e-04.\n",
      "Epoch number: 1 and the loss : 11.16543960571289\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0002)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max = 100, verbose = True)\n",
    "\n",
    "epochs = 2\n",
    "#final_loss = []\n",
    "for i in range(epochs):\n",
    "  #for ii in range(len(data_loader)):\n",
    "  for ii, data_train in enumerate(tqdm(data_loader), 0):\n",
    "    print(i, ii)\n",
    "    rgb_gt = data_train[0].unsqueeze(0).to('cuda')\n",
    "\n",
    "    rgb_noisy, mask = expand2square(data_train[1].cuda(), factor=128)\n",
    "    rgb_noisy, mask = rgb_noisy.to('cuda'), mask.to('cuda')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # print(rgb_gt)\n",
    "    # Forward pass\n",
    "    outputs = model(rgb_noisy)\n",
    "    #outputs = model(rgb_noisy, 1 - mask)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_function(outputs, rgb_gt)\n",
    "    # final_loss.append(loss)\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if ii == 5:\n",
    "      break\n",
    "\n",
    "  scheduler.step()\n",
    "  print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
    "\n",
    "  torch.save({\n",
    "            'epoch': i,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            #'loss': loss,\n",
    "            }, '/kaggle/working/checkpoint.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d6e7250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:54.182284Z",
     "iopub.status.busy": "2023-10-07T16:03:54.181381Z",
     "iopub.status.idle": "2023-10-07T16:03:54.797904Z",
     "shell.execute_reply": "2023-10-07T16:03:54.796769Z"
    },
    "id": "y_EbTgvo7Qr0",
    "papermill": {
     "duration": 0.635099,
     "end_time": "2023-10-07T16:03:54.801140",
     "exception": false,
     "start_time": "2023-10-07T16:03:54.166041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/kaggle/working/checkpoint.pth')\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "#loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "748fb678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T16:03:54.859140Z",
     "iopub.status.busy": "2023-10-07T16:03:54.858635Z",
     "iopub.status.idle": "2023-10-07T16:03:54.865316Z",
     "shell.execute_reply": "2023-10-07T16:03:54.864486Z"
    },
    "papermill": {
     "duration": 0.039381,
     "end_time": "2023-10-07T16:03:54.869997",
     "exception": false,
     "start_time": "2023-10-07T16:03:54.830616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de86298",
   "metadata": {
    "papermill": {
     "duration": 0.026494,
     "end_time": "2023-10-07T16:03:54.924096",
     "exception": false,
     "start_time": "2023-10-07T16:03:54.897602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 107.642524,
   "end_time": "2023-10-07T16:03:57.571419",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-07T16:02:09.928895",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
